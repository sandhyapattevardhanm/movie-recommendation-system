{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64191382",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8f82d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\SINISTER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\SINISTER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re # regular expression library\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "def normalize(text):\n",
    "    # Replace with whitespace to separate '😃\\n\\nFor'\n",
    "    text = text.replace(r\"\\n\", r\" \")\n",
    "    text = text.replace(r\"\\r\", r\" \")\n",
    "    # Drop puntuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Remove extra spaces from '😃  For' to '😃 For'\n",
    "    text = re.sub(r\"\\s+\", r\" \", text)\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    # Remove leading and trailing whitespace\n",
    "    text = text.strip()\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    #lower case the all capital alphabets\n",
    "    text=text.lower()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens=word_tokenize(text)\n",
    "    text = ' '.join([word for word in word_tokens if word not in stop_words])\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "864febce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer=Tokenizer()\n",
    "\n",
    "def tok_vectorizer(text):\n",
    "  test_sequences = tokenizer.texts_to_sequences(text)\n",
    "  X_test_padded = pad_sequences(test_sequences, maxlen=35)\n",
    "  return X_test_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d7b0632c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "daa64750",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model(\"text_based_emotion_classifier.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1d0eb7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"getting scared\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "37434ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=normalize(text)\n",
    "x=tok_vectorizer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "863830d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step\n"
     ]
    }
   ],
   "source": [
    "a=model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "439230d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1712919 , 0.16859983, 0.1610882 , 0.17817102, 0.16448042,\n",
       "       0.15636863], dtype=float32)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "34ce9d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mood=sadness (0), joy (1), love (2), anger (3), fear (4),lazy(5)\n",
    "mood=np.argmax(a[0],axis=0)\n",
    "mood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "cc02336f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'anger'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mood_dict={0:'sadness',1:'joy',2:'love',3:'anger',4:'fear',5:'lazy'}\n",
    "text_mood=str(mood_dict[mood])\n",
    "text_mood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e50eb5f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Action'"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mood_to_genre = {\n",
    "    'sad': 'Drama',\n",
    "    'joy': 'Comedy',\n",
    "    'love': 'Romance',\n",
    "    'anger': 'Action',\n",
    "    'fear': 'Horror',\n",
    "    'lazy': 'Relaxation'\n",
    "}\n",
    "genre=str(mood_to_genre[text_mood])\n",
    "genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "b774261c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recommender\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"movie_dataset.csv\")\n",
    "\n",
    "# Fill missing values for the specified features\n",
    "features = ['keywords', 'cast', 'genres', 'director']\n",
    "for feature in features:\n",
    "    df[feature] = df[feature].fillna('')\n",
    "\n",
    "# Combine features into a single string\n",
    "def combined_features(row):\n",
    "    return row['keywords'] + \" \" + row['cast'] + \" \" + row['genres'] + \" \" + row['director']\n",
    "\n",
    "df['combined_features'] = df.apply(combined_features, axis=1)\n",
    "\n",
    "# Create a CountVectorizer and transform the combined features\n",
    "cv = CountVectorizer()\n",
    "count_matrix = cv.fit_transform(df['combined_features'])\n",
    "\n",
    "# Calculate cosine similarity\n",
    "cosine_sim = cosine_similarity(count_matrix)\n",
    "\n",
    "def recommend_movies(genre, title, top_n=10):\n",
    "    # Check if the movie title is in the dataset\n",
    "    if title not in df['title'].values:\n",
    "        raise ValueError(\"Movie title not found in dataset\")\n",
    "    \n",
    "    # Get the index of the movie with the given title\n",
    "    def get_index_from(title):\n",
    "        return df[df['title'] == title].index.values[0]\n",
    "\n",
    "    movie_index = get_index_from(title)\n",
    "    \n",
    "    # Get similarity scores\n",
    "    similar_movies = list(enumerate(cosine_sim[movie_index]))\n",
    "    \n",
    "    # Sort movies based on similarity score\n",
    "    sorted_similar_movies = sorted(similar_movies, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Function to get movie title from index\n",
    "    def get_title_from_index(index):\n",
    "        return df.iloc[index]['title']\n",
    "    \n",
    "    # Recommend movies of the specified genre\n",
    "    recommendations = []\n",
    "    for movie in sorted_similar_movies:\n",
    "        idx = movie[0]\n",
    "        if len(recommendations) >= top_n:\n",
    "            break\n",
    "        if df.iloc[idx]['genres'] == genre and df.iloc[idx]['title'] != title:\n",
    "            recommendations.append(df.iloc[idx]['title'])\n",
    "    \n",
    "    return recommendations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "fedcdfa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter title: Avatar\n",
      "your current mood is anger\n"
     ]
    }
   ],
   "source": [
    "title = input('enter title: ')\n",
    "print('your current mood is',text_mood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "87255bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended movies similar to 'Avatar' in genre 'Action':\n",
      "['Furious 7', 'Once Upon a Time in Mexico', 'Stealth', 'Excessive Force', 'Only the Strong', 'Pound of Flesh', 'Alatriste', 'Out of Inferno', 'State of Play', 'Max Payne']\n"
     ]
    }
   ],
   "source": [
    "recommended_movies = recommend_movies(genre, title)\n",
    "print(f\"Recommended movies similar to '{title}' in genre '{genre}':\")\n",
    "print(recommended_movies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
